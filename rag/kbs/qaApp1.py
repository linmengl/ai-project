import os
import gradio as gr
from llama_index.core import SimpleDirectoryReader, VectorStoreIndex, Settings
from llama_index.embeddings.huggingface import HuggingFaceEmbedding
from llama_index.llms.ollama import Ollama

UPLOAD_DIR = "docs"
INDEX_DIR = "storage"
os.makedirs(UPLOAD_DIR, exist_ok=True)

# ç¦ç”¨ tokenizer å¹¶è¡ŒåŠ é€Ÿé¿å…å‘Šè­¦
os.environ["TOKENIZERS_PARALLELISM"] = "false"

# 1. åˆå§‹åŒ– LLM
Settings.llm = Ollama(
    model="llama3:8b",
    system_prompt="ä½ æ˜¯ä¸€ä¸ªä¸­æ–‡åŠ©æ‰‹ï¼Œè¯·å§‹ç»ˆä½¿ç”¨ç®€ä½“ä¸­æ–‡å›ç­”é—®é¢˜ã€‚",
    temperature=0.7)

embedding = HuggingFaceEmbedding(model_name="shibing624/text2vec-base-multilingual")

# æ–‡æ¡£å¤„ç†é€»è¾‘
def build_index():
    documents = SimpleDirectoryReader(UPLOAD_DIR).load_data()
    print("Building index...")
    index = VectorStoreIndex.from_documents(documents, embed_model = embedding)
    index.storage_context.persist(persist_dir=INDEX_DIR)
    return index

# æ„å»ºç´¢å¼•ç¼“å­˜
doc_index = build_index()
query_engine = doc_index.as_query_engine()

# é—®ç­”æ¥å£
def ask_question(question):
    # retriever = doc_index.as_retriever(similarity_top_k=20)
    # nodes = retriever.retrieve(question)
    # for i, node in enumerate(nodes):
    #     print(f"æ–‡æ¡£ç‰‡æ®µ {i + 1}:\n", node.text[:800])
    response = query_engine.query(question)
    return str(response)


# ä¸Šä¼ æ¥å£
def upload_file(files):
    for file in files:
        print(f"type of file: {type(file)}, value: {file}")
        filename = os.path.basename(file)
        print("ä¸Šä¼ æ–‡ä»¶ï¼š" + filename)
        file_write_path = os.path.join(UPLOAD_DIR, filename)
        print("æ–‡ä»¶å†™å…¥è·¯å¾„ï¼š"+file_write_path)
        # ä»¥äºŒè¿›åˆ¶åªè¯»æ¨¡å¼æ‰“å¼€ä¸Šä¼ æ–‡ä»¶ï¼ˆè·¯å¾„ç”± gr.File(..., type="filepath") è¿”å›
        with open(file, "rb") as src, open(file_write_path, "wb") as dst:
            dst.write(src.read())
    global doc_index, query_engine
    doc_index = build_index()
    query_engine = doc_index.as_query_engine()
    print("âœ… æ–‡ä»¶ä¸Šä¼ å¹¶æ›´æ–°ç´¢å¼•æˆåŠŸ")

# Gradio ç•Œé¢
with gr.Blocks() as demo:
    gr.Markdown("# ğŸ“„ æ–‡æ¡£é—®ç­”ç³»ç»Ÿ (æ”¯æŒ PDF, Word, Markdown, TXT)")

    with gr.Row():
        # æ–‡ä»¶ä¸Šä¼ ç»„ä»¶
        file_upload = gr.File(
            label="ä¸Šä¼ æ–‡æ¡£",
            file_types=[".pdf", ".docx", ".md", ".txt"],
            type="filepath",
            file_count="multiple"
        )
    upload_btn = gr.Button("ä¸Šä¼ å¹¶æ„å»ºç´¢å¼•")
    upload_result = gr.Textbox(label="ä¸Šä¼ çŠ¶æ€")
    upload_btn.click(upload_file, inputs=file_upload, outputs=upload_result)

    gr.Markdown("## ğŸ’¬ å¼€å§‹æé—®")
    question = gr.Textbox(label="ä½ çš„é—®é¢˜", placeholder="è¯·é—®è¿™ä¸ªæ–‡æ¡£è®²äº†ä»€ä¹ˆï¼Ÿ")
    answer = gr.Textbox(label="å›ç­”")
    ask_btn = gr.Button("æé—®")
    ask_btn.click(ask_question, inputs=question, outputs=answer)

if __name__ == "__main__":
    demo.launch(share=True)

